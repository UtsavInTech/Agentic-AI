{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixs2UuWy6CNT"
   },
   "source": [
    "**Objective**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVgN4G2Z6Lm2"
   },
   "source": [
    "The objective of this task is to fine-tune a Small Language Model (SLM) with less than 3B parameters on a text dataset from Hugging Face, evaluate its performance, and analyze results using suitable metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "twjuimNy4wch",
    "outputId": "c8d52ba5-a116-4de9-c7f0-d3c4a2292922"
   },
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "!pip install -q transformers datasets accelerate evaluate sentencepiece torch\n",
    "\n",
    "# Optional (for faster training + metrics)\n",
    "!pip install -q scikit-learn tqdm\n",
    "!pip install -U transformers accelerate datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlfLD8Nw6lqB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySFeyeV66pkW"
   },
   "source": [
    "## Dataset Selection\n",
    "\n",
    "- **Dataset Chosen**\n",
    "  - **Dataset:** `yelp_review_full`\n",
    "  - **Source:** Hugging Face\n",
    "  - **Reason for Selection:**\n",
    "    - Pure text dataset\n",
    "    - Sufficient size for language modeling\n",
    "    - Different from common datasets like WikiText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93tj-vMZ7rrR",
    "outputId": "d58f472d-2b76-44a1-88f2-f8e2267e2caa"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bGR6IEG76XW"
   },
   "source": [
    "## Model Selection\n",
    "\n",
    "### Selected Small Language Model\n",
    "\n",
    "- **Model:** `distilgpt2`  \n",
    "- **Parameters:** ~82M (well under 3B)\n",
    "\n",
    "### Reason for Selection\n",
    "\n",
    "- Lightweight  \n",
    "- Fast to fine-tune  \n",
    "- Suitable for Google Colab GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "28efa8d4e2834feb9e9195fb9273f63a",
      "066892f7ec234659b0fcac5151fc667f",
      "ae0c44a0bd394cc48dc118d03d24cffa",
      "8f6274ab78dc4d7fac8e081f166a43ad",
      "3513e1c5c284433bbcc1a4c3aefe9074",
      "3aea043a20db4b96ad7565c7f3772539",
      "3e9c27ec45f949cf9313070970fc7c85",
      "d84d53ec474443fb904779d4789163b0",
      "a674b5f1ef954c4697a14e9197fd43a3",
      "c66a921c72fe47e8b8fb9e16a042ce37",
      "bad9b22f6db849008d2eac3ed229854d"
     ]
    },
    "id": "sBEEodeG8XQk",
    "outputId": "36f06181-7117-4da2-dbee-c180a0fc4752"
   },
   "outputs": [],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4EBlRzx8izt"
   },
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "025e9b9fb246434392203a844b043ba7",
      "d15240491778474e91c8e4c652a936a1",
      "0fe77b0d00d3432c8884d91dcc1a9c07",
      "5eef21978b0144c8be35430f0e5e8e36",
      "a9948b4cb55c45abaee5245ce6b37333",
      "02f0220789b34a2b81856884ba0b9c54",
      "112c8879bd53415d9d55618f548f7559",
      "645b4c2fc51546d09f63dd9e9f5487b5",
      "24db5918420143eca7c0ac4fda5cdcad",
      "7a367cf3406a4ddd831cca024469aebe",
      "822895fce2c74fbc8cbe68b653d067af",
      "c9db224055244ac7bae7f054f38a5632",
      "4193f91b2fa344eb92cedbe9d4d658c6",
      "e6b4e155bb5748d19dd0d043904390bf",
      "00fef6d5ae9f4a21a2cc4dd50bed24ef",
      "06bbe734ddc14f98b11745e2a219ea12",
      "fde1d77dc5b8490b83dd4a9feeb4f4d0",
      "9bdf9db5b905428cafcd1a9ead24aa57",
      "131cc41b063342edb811afe24799778f",
      "4729d30f57e64a58908373d4fd67db3d",
      "d78a3760bba24769ae7fbb9025c694ba",
      "bc4717234d7f45e1959728471c43015f"
     ]
    },
    "id": "ECBSuV908pWo",
    "outputId": "6ba0c19e-9be1-4c26-dfc0-ee6cb04d6d77"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hn9h9d98uKL"
   },
   "source": [
    "**Data Collator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdEQXSuz8xIy"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqjK2psd80gv"
   },
   "source": [
    " **Training Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zf7wdb3L83aG",
    "outputId": "78fe2921-2bff-4158-a1f9-7f529a87da8b"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  # OLD API COMPATIBLE\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VnEj4JK9HI3"
   },
   "source": [
    "**Trainer Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSh_Sckm9MmZ"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42).select(range(5000)),\n",
    "    eval_dataset=tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000)),\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306,
     "referenced_widgets": [
      "6079b7fa077f4f88b7cfaff84c54d2d8",
      "38b336c619e64f34b5195a5480c0b5a3",
      "5f5e57e62cda4a1684c9a4a50a480f6d",
      "1293d19eb5244e55944a85d1982489da",
      "8456ac386deb4b4da346075779ff844b",
      "8c193991273747218dd1386dd57767e7",
      "6c2032643e8c4341b11f3c446749c723",
      "0883d50b2c4b4a2bab8c31969cd4d320",
      "63c64654f05c43c19f35e5d7e474fb9b",
      "51435ac3b01540188851a13d3ef22752",
      "1c35290d2a2a4a2a9962dac1e15f1dd0",
      "74c1c7ba328e4624b8cfb0427f08f1b8",
      "87d316d15646424fbc4ce8087fddc088",
      "331cdaf773df4befb9fb91c2b3c62dd3",
      "0052cf0f84e84b35b41c1d28d2065471",
      "984c1b8d71994ea0b23ea67e3e9bdea0",
      "66228984e21341f298b79f175e44e11c",
      "95d17d56354b429eab30934342b7b100",
      "0f887d4f0e244209b144f56615a2b8de",
      "1cd118d50cfb441dbddf7b142cac60af",
      "e100ce4e5d1b4a9583e772f35c17b4c7",
      "ec02b95a71704c7c8dee7790f2d89fb2",
      "c0744c44c73a477bae18242321402319",
      "16b5447d6d4a4d10888d12e6fa98c715",
      "4ac09c62719c4ccba8a489b13dc8e4fe",
      "12c63ff4450d4d4aa470e18e0418c391",
      "301f9879bebf453ca4d299d55f723af1",
      "0eb05f2cda5b401a9decee35c4b0f81c",
      "67d7d2a838af47b7aded800134f1e168",
      "2d725083356a4b62a1e66d897c6757cf",
      "af52bb5ba6a44d9cbfc880fb4f93bc85",
      "b30a8bc7eb814a26aa62091bd9d31685",
      "679afa5ab6ab46cb8e916ede2341beda"
     ]
    },
    "id": "uL2anPmO9PSz",
    "outputId": "a23ca8da-3bf2-44dd-9313-422b46d7444f"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kLxF2ne9SNh"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "### Metric Used\n",
    "\n",
    "- **Perplexity**  \n",
    "  - Standard evaluation metric for language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "FaxYgDzp9Ze2",
    "outputId": "58797c08-e8ac-47b9-c697-0ee8c122d51e"
   },
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "\n",
    "perplexity = torch.exp(torch.tensor(eval_results[\"eval_loss\"]))\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CDeKEKT9dVs"
   },
   "source": [
    "**Text Generation Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZp6bL-q9gzS",
    "outputId": "7dd52330-957f-49d2-e926-3e6047f6fef0"
   },
   "outputs": [],
   "source": [
    "prompt = \"The food at this restaurant was\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq2msI7l9jZ-"
   },
   "source": [
    "14. Results\n",
    "\t-\tTraining Loss: Reduced over epochs\n",
    "\t-\tEvaluation Loss: Stable\n",
    "\t-\tPerplexity: Improved compared to base model\n",
    "\t-\tGenerated Text: More coherent and sentiment-aware\n",
    "\n",
    "\n",
    "15. Observations\n",
    "\t1.\tFine-tuning even a small model significantly improves domain-specific text generation.\n",
    "\t2.\tYelp reviews help the model learn sentiment and food-related language patterns.\n",
    "\t3.\tSmaller batch sizes are effective for Colab GPUs.\n",
    "\t4.\tDistilGPT-2 is suitable for educational fine-tuning tasks.\n",
    "\n",
    "\n",
    "16. Conclusion\n",
    "\n",
    "This experiment demonstrates that Small Language Models (<3B) can be efficiently fine-tuned using limited compute resources. The model showed improved fluency and contextual understanding after fine-tuning."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
